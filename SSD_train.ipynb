{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\komleva-ep/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    }
   ],
   "source": [
    "#Load model\n",
    "import torch\n",
    "precision = 'fp32'\n",
    "ssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd', model_math=precision)\n",
    "#print(ssd_model --help)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes=4):\n",
    "\n",
    "    model = resnet50(pretrained=True)\n",
    "    num_feats = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_feats, num_classes)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(dataset_dirs):\n",
    "\n",
    "    train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    valid_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                    transforms.CenterCrop(224),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    train_dataset = ImageFolderWithSubfolders(root='../data/input/train',\n",
    "                                              transform=train_transform,\n",
    "                                              subfolders=dataset_dirs)\n",
    "    valid_dataset = ImageFolderWithSubfolders(root='../data/input/valid',\n",
    "                                              transform=valid_transform,\n",
    "                                              subfolders=dataset_dirs)\n",
    "\n",
    "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "    valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    return train_dataloader, valid_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, valid_dataloader, plot=False):\n",
    "    print(valid_dataloader.dataset.class_to_idx)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        result = 0\n",
    "        n = 0\n",
    "        val_preds = np.zeros(len(valid_dataloader.dataset))\n",
    "        val_labels = np.zeros(len(valid_dataloader.dataset))\n",
    "        start = 0\n",
    "        general_classifier = GeneralClassifier()\n",
    "        for images, labels in valid_dataloader:\n",
    "            batch_size = images.size(0)\n",
    "            n += batch_size\n",
    "            #images = images.cuda()\n",
    "            #img = preprocess_for_ssd(general_classifier, images)\n",
    "            #print(img)\n",
    "            #pred = F.softmax(model(img))\n",
    "            pred  = 0.5#person_predict(general_classifier, images)\n",
    "            prediction = torch.argmax(pred, 1)\n",
    "\n",
    "            val_preds[start:start + batch_size] = prediction.cpu().numpy()\n",
    "            val_labels[start:start + batch_size] = labels.numpy()\n",
    "            start += batch_size\n",
    "\n",
    "    print('Precision: ', precision_score(val_labels, val_preds, average='weighted'))\n",
    "    print('Recall: ', recall_score(val_labels, val_preds, average='weighted'))\n",
    "    print('F1 score: ', f1_score(val_labels, val_preds, average='weighted'))\n",
    "\n",
    "    if plot:\n",
    "        cm = confusion_matrix(val_labels, val_preds,\n",
    "                              labels=list(valid_dataloader.dataset.class_to_idx.values()))\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                      display_labels=list(valid_dataloader.dataset.class_to_idx.keys()))\n",
    "        #disp.plot()\n",
    "        \n",
    "        disp.plot(cmap = plt.cm.Blues)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, valid_dataloader, start_epoch=0, num_epochs=5, plot=False):\n",
    "    #model.cuda()\n",
    "    #optimizer = optim.Adam(params=model.fc.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    losses = []\n",
    "    for epoch in range(start_epoch,num_epochs):\n",
    "        print(epoch)\n",
    "        model.train()\n",
    "        for images, labels in tqdm(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            #images = images.cuda()\n",
    "            #labels = labels.cuda()\n",
    "            pre_img = preprocess_for_ssd(images)\n",
    "            pred = model(pre_img)\n",
    "            loss = criterion(pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        eval_model(model, valid_dataloader)\n",
    "        #torch.save(model, '../checkpoints/text_classifier_{}.pt'.format(epoch+1))\n",
    "        torch.save(model, '../checkpoints/text_classifier_2cats_{}.pt'.format(epoch+1))\n",
    "        if plot:\n",
    "            plt.plot(losses)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def person_predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            img = self.preprocess_for_ssd(x)\n",
    "            ssd_predictions = self.person_detector(img)\n",
    "            ssd_results = self.person_detection_utils.decode_results(ssd_predictions)\n",
    "            bboxes, classes, confidences = self.person_detection_utils.pick_best(ssd_results[0], 0.40)\n",
    "            max_person_conf = 0\n",
    "            for cat, conf in zip(classes, confidences):\n",
    "                if cat == 1 and conf > max_person_conf:\n",
    "                    max_person_conf = conf\n",
    "        return 'person: {:.2f}'.format(max_person_conf)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def preprocess_for_ssd( image):\n",
    "        #print(image)\n",
    "        #im = Image.open(\"a0.01dg0.30d0.08g0.02h0.54n0.03p0.02gr0.00ne1.00per0.62.png\")\n",
    "        #np_im = numpy.array(im)\n",
    "        #print (np_im.shape)\n",
    "\n",
    "        #np_im = np_im - 18\n",
    "        #img = Image.fromarray(np_im)\n",
    "        img = Image.fromarray(image)\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((300, 300)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        img = transform(img)\n",
    "        img = img.to(self.device)\n",
    "        img = img.unsqueeze(0)\n",
    "        return img    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7389885807504079\n"
     ]
    }
   ],
   "source": [
    "print((613-160)/(613-160+160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute '__array_interface__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-b822058b1ace>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m#model = train_model(model, train_dataloader, valid_dataloader, start_epoch=0, num_epochs=15)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m#eval_model(model, valid_dataloader, plot=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m#eval_model_2clasees(model, valid_dataloader, negative_classes=['drugs', 'gore', 'hentai', 'porn', 'drawing_gore',  'animals'],\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-ee6b49c485df>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_dataloader, valid_dataloader, start_epoch, num_epochs, plot)\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;31m#images = images.cuda()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;31m#labels = labels.cuda()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mpre_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_for_ssd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-b06be3897a3a>\u001b[0m in \u001b[0;36mpreprocess_for_ssd\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m#np_im = np_im - 18\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m#img = Image.fromarray(np_im)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         transform = transforms.Compose([\n\u001b[0;32m     26\u001b[0m             \u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\premoderation_img\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   2737\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mversionadded\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1.1\u001b[0m\u001b[1;36m.6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2738\u001b[0m     \"\"\"\n\u001b[1;32m-> 2739\u001b[1;33m     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__array_interface__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2740\u001b[0m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2741\u001b[0m     \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute '__array_interface__'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay,\\\n",
    "    accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import ImageFolderWithSubfolders\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    dataset_dirs = ['pearson', 'no_pearson']\n",
    "    train_dataloader, valid_dataloader = get_dataloaders(dataset_dirs)\n",
    "    #model = create_model(7)#.cuda()\n",
    "    model = ssd_model#torch.load('../checkpoints/best_nswf_classifeir.pt')#.cuda()\n",
    "    #model = train_model(model, train_dataloader, valid_dataloader, start_epoch=0, num_epochs=15)\n",
    "    #eval_model(model, valid_dataloader, plot=True)\n",
    "    model = train_model(model, train_dataloader, valid_dataloader, start_epoch=0, num_epochs=10)\n",
    "    \n",
    "    #eval_model_2clasees(model, valid_dataloader, negative_classes=['drugs', 'gore', 'hentai', 'porn', 'drawing_gore',  'animals'],\n",
    "    #                    positive_classes=['neutral'], plot=True)\n",
    "    #torch.save(model.state_dict(), '../checkpoints/model_7dirs_5.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy\n",
    "im = Image.open(\"a0.01dg0.30d0.08g0.02h0.54n0.03p0.02gr0.00ne1.00per0.62.png\")\n",
    "np_im = numpy.array(im)\n",
    "#print (np_im.shape)\n",
    "\n",
    "#np_im = np_im - 18\n",
    "new_im = Image.fromarray(np_im)\n",
    "#print(np_im)\n",
    "new_im.save(\"numpy_altered_sample2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "####################\n",
    "import cv2\n",
    "#####################\n",
    "from general_model import GeneralClassifier \n",
    "general_classifier = GeneralClassifier()\n",
    "full_filename = r'a0.01dg0.30d0.08g0.02h0.54n0.03p0.02gr0.00ne1.00per0.62.png'\n",
    "x = cv2.imread(full_filename)\n",
    "cv2. imshow(\"IMG\",x)\n",
    "person_string = person_predict(general_classifier,x)\n",
    "print(person_string)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ''\n",
    "for i in range(111):\n",
    "    s= s+'0'+ ','\n",
    "print(s)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "y_actu = [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, 0,0,1,1, 1, 1,0,0,1]\n",
    "y_pred = [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1, 1, 0, 0 , 0 ,0,1,1 ,0 ]\n",
    "labels = np.unique(y_pred)\n",
    "cm = confusion_matrix(y_actu, y_pred, labels =labels)\n",
    "#cm = confusion_matrix(val_labels, val_preds, labels=list(valid_dataloader.dataset.class_to_idx.values()))\n",
    "#cm = confusionchart([0 ,2 ],{'apple','watermelon'})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['not people', 'people'])\n",
    "#disp.plot()\n",
    "\n",
    "#fig = plt.figure()        \n",
    "disp.plot(cmap = plt.cm.Blues)\n",
    "plt.title('SSD confusion matrix')\n",
    "#plt.xticks(rotation=45)\n",
    "#fig.suptitle('test title', fontsize=20)\n",
    "plt.show()\n",
    "plt.savefig('cm.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "import torch.optim as optim # For all Optimization algorithms, SGD, Adam, etc.\n",
    "import torch.nn.functional as F # All functions that don't have any parameters\n",
    "from torch.utils.data import DataLoader # Gives easier dataset managment and creates mini batches\n",
    "import torchvision.datasets as datasets # Has standard datasets we can import in a nice way\n",
    "import torchvision.transforms as transforms # Transformations we can perform on our dataset\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyperparameters\n",
    "num_classes = 10 \n",
    "learning_rate = 1e-3\n",
    "batch_size = 1024\n",
    "num_epochs = 5\n",
    "\n",
    "# Simple Identity class that let's input pass without changes\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "# Load pretrain model & modify it\n",
    "model = #torchvision.models.vgg16(pretrained=True)\n",
    "\n",
    "# If you want to do finetuning then set requires_grad = False\n",
    "# Remove these two lines if you want to train entire model,\n",
    "# and only want to load the pretrain weights.\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "model.avgpool = Identity()\n",
    "model.classifier = nn.Sequential(nn.Linear(512, 100),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(100, num_classes))\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Load Data\n",
    "train_dataset = datasets.CIFAR10(root='dataset/', train=True, \n",
    "                                 transform=transforms.ToTensor(), download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train Network\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Get data to cuda if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        \n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "    print(f'Cost at epoch {epoch} is {sum(losses)/len(losses):.5f}')\n",
    "\n",
    "# Check accuracy on training & test to see how good our model\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print(\"Checking accuracy on training data\")\n",
    "    else:\n",
    "        print(\"Checking accuracy on test data\")\n",
    "        \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            \n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "        \n",
    "        print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}') \n",
    "    \n",
    "    model.train()\n",
    "\n",
    "check_accuracy(train_loader, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge ipywidgets\n",
    "jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
